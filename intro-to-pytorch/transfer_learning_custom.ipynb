{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Reference: [PyTorch documnetation](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Cat_Dog_data\"\n",
    "\n",
    "imagenet_stats = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
    "\n",
    "data_transforms = {'train': transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(*imagenet_stats)]),\n",
    "                   'test': transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(*imagenet_stats)])\n",
    "                  }\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                 for x in ['train','test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],batch_size=16,shuffle=True,num_workers=2) \n",
    "              for x in ['train','test']}\n",
    "\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(image_datasets['train'].classes)\n",
    "image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "nf = model.fc.in_features\n",
    "model.fc = nn.Linear(nf,num_classes)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,5,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "    def append(self,current):\n",
    "        self.logs.append(current)\n",
    "        \n",
    "    def show(self):\n",
    "        clear_output(wait=True)\n",
    "        df = pd.DataFrame(self.logs)\n",
    "        display(HTML(df.to_html()))\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,dls,model,loss_func,optimizer,scheduler=None):\n",
    "        self.dls,self.model = dls, model\n",
    "        self.optimizer,self.scheduler = optimizer,scheduler\n",
    "        self.criterion = loss_func\n",
    "        self.ds_sizes = {x: len(dls[x]) for x in ['train','test']}\n",
    "        self.logger = Logger()\n",
    "    \n",
    "    def fit(self,epochs,steps=None):\n",
    "        self.model.train()        \n",
    "        for e in range(epochs):\n",
    "            running_loss = 0.\n",
    "            running_accuracy = 0.\n",
    "            for idx, (images, labels) in enumerate(self.dls['train']):\n",
    "                if idx+1 == steps:\n",
    "                    break\n",
    "                \n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs,labels)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    if self.scheduler is not None:\n",
    "                        self.scheduler.step()\n",
    "                    \n",
    "                    running_loss += loss.item()\n",
    "                    correct = outputs.argmax(-1)==labels[None]\n",
    "                    running_accuracy += torch.mean(correct.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            test_logs = self.evaluate(steps)\n",
    "            \n",
    "            div_factor = self.ds_sizes['train'] if steps is None else steps\n",
    "            \n",
    "            logs = {'epoch':e,\n",
    "                    'train_loss':running_loss/div_factor,\n",
    "                    'train_accuracy':running_accuracy/div_factor,\n",
    "                     **test_logs}\n",
    "            \n",
    "            self.logger.append(logs)\n",
    "            self.logger.show()\n",
    "    \n",
    "    def evaluate(self,steps=None):\n",
    "        \"Evaluate on test dataset\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_accuracy = 0.\n",
    "            for idx, (images,labels) in enumerate(self.dls['test']):\n",
    "                if steps is not None and idx+1==steps:\n",
    "                    break\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs,labels)\n",
    "                correct = outputs.argmax(-1)==labels\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_accuracy += torch.mean(correct.type(torch.FloatTensor)).item()\n",
    "            \n",
    "\n",
    "            div_factor = self.ds_sizes['test'] if steps is None else steps\n",
    "            \n",
    "            logs = {'test_loss': running_loss / div_factor,\n",
    "                   'test_accuracy': running_accuracy / div_factor}\n",
    "            \n",
    "            return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dataloaders,model,nn.CrossEntropyLoss(),optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.549134</td>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.294270</td>\n",
       "      <td>0.83750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.812275</td>\n",
       "      <td>0.68125</td>\n",
       "      <td>0.373479</td>\n",
       "      <td>0.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.400133</td>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.364354</td>\n",
       "      <td>0.80625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.583836</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.374108</td>\n",
       "      <td>0.80625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.363689</td>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.303404</td>\n",
       "      <td>0.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.775697</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.288825</td>\n",
       "      <td>0.83125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.354549</td>\n",
       "      <td>0.80625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.634965</td>\n",
       "      <td>0.71250</td>\n",
       "      <td>0.400485</td>\n",
       "      <td>0.81875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.328406</td>\n",
       "      <td>0.81875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.367845</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.415547</td>\n",
       "      <td>0.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.544440</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.231801</td>\n",
       "      <td>0.81875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.79375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.519330</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.265177</td>\n",
       "      <td>0.82500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.468975</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.352392</td>\n",
       "      <td>0.79375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.439118</td>\n",
       "      <td>0.74375</td>\n",
       "      <td>0.344678</td>\n",
       "      <td>0.80625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.595856</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.388458</td>\n",
       "      <td>0.83125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.314425</td>\n",
       "      <td>0.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.401233</td>\n",
       "      <td>0.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.703397</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.523095</td>\n",
       "      <td>0.74375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.463769</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.206102</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(20,steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
